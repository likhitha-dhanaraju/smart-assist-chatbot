{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation for Image Captioning models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2d70a72a5068f31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installing and Importing libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "775b91bb1d8d37bb"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-18T10:00:24.539756500Z",
     "start_time": "2024-03-18T10:00:24.500218Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import string\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_folder = r\"C:\\\\Users\\\\likhi\\\\Documents\\\\02 Pycharm Datasets\\\\01 Master Thesis\\\\04 Product Data\\\\\"\n",
    "destination_image_dir = r'C:\\\\Users\\\\likhi\\\\Documents\\\\02 Pycharm Datasets\\\\01 Master Thesis\\\\06b Image_Captioning_Dataset\\\\imagefolder\\\\'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T10:00:24.549148700Z",
     "start_time": "2024-03-18T10:00:24.544769400Z"
    }
   },
   "id": "fd20530d7f3df1a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "15fe9f8f4f899f9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the train - val - test split of dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9814f9fcc5749c67"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def clean_descriptions(desc):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    desc = desc.split(' ')\n",
    "    desc = [word.lower() for word in desc]\n",
    "    desc = [w.translate(table) for w in desc]\n",
    "    desc = [word for word in desc if len(word)>1]\n",
    "    desc = ' '.join(desc)\n",
    "    \n",
    "    return desc\n",
    "\n",
    "\n",
    "# Function to create train, validation, and test directories\n",
    "def create_directories(root_dir, subdirs):\n",
    "    for subdir in subdirs:\n",
    "        os.makedirs(os.path.join(root_dir, subdir), exist_ok=True)\n",
    "\n",
    "# Function to copy files to train, validation, and test directories\n",
    "def copy_to_split(image_path, destination_dir, split):\n",
    "    shutil.copy(image_path, os.path.join(destination_dir, split))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T10:00:24.564294100Z",
     "start_time": "2024-03-18T10:00:24.549148700Z"
    }
   },
   "id": "2e4784f44a294a9b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [1:03:42<00:00, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files and split directories created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to process a single product\n",
    "def process_product(product_folder, category_path, destination_image_dir, train_ratio, val_ratio):\n",
    "    all_images = []\n",
    "    product_path = os.path.join(category_path, product_folder)\n",
    "   \n",
    "    try:\n",
    "        data = json.load(open(os.path.join(product_path, product_folder + \".json\"), \"r\"))\n",
    "        product_overview = data.get('product_overview', '')\n",
    "        product_overview = \",\".join([key + \" is \" + value for key, value in product_overview.items() \n",
    "                            if key.lower() not in ['color', 'colour']])\n",
    "        product_description = \",\".join(data.get('description', ''))\n",
    "        categories = \",\".join(data.get('categories', ''))\n",
    "        product_title = data.get('Title', '')\n",
    "        final_description = product_title + categories + product_description + product_overview\n",
    "        \n",
    "        cleaned_final_description = clean_descriptions(final_description)\n",
    "        \n",
    "        image_names = [i for i in os.listdir(product_path) if '.jpg' in i]\n",
    "        all_images.extend(image_names)\n",
    "\n",
    "        if len(cleaned_final_description) > 0:\n",
    "            for img in image_names:\n",
    "                product_dict = {}  # Create a new dictionary for each iteration\n",
    "                product_dict[\"file_name\"] = img\n",
    "                product_dict[\"text\"] = cleaned_final_description\n",
    "                \n",
    "                # Write the dictionary to the appropriate output file based on the split\n",
    "                rand = random.random()\n",
    "                if rand < train_ratio:\n",
    "                    train_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "                 \n",
    "                elif rand < train_ratio + val_ratio:\n",
    "                    val_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "                else:\n",
    "                    test_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "                \n",
    "                # Copy images to the appropriate split directories\n",
    "                rand = random.random()\n",
    "                if rand < train_ratio:\n",
    "                    copy_to_split(os.path.join(product_path, img), destination_image_dir, 'train')\n",
    "                elif rand < train_ratio + val_ratio:\n",
    "                    copy_to_split(os.path.join(product_path, img), destination_image_dir, 'val')\n",
    "                else:\n",
    "                    copy_to_split(os.path.join(product_path, img), destination_image_dir, 'test')\n",
    "                \n",
    "    except Exception as e:\n",
    "        pass\n",
    "        # print(f\"Error processing product {product_folder}: {e}\")\n",
    "        # print(f\"Path to product folder: {product_path}\")\n",
    "        # print(f\"Content of product folder: {os.listdir(product_path)}\")\n",
    "\n",
    "\n",
    "# Initialize lists to keep track of product names\n",
    "all_product_names = []\n",
    "\n",
    "# Define train-val-test split ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Create train, validation, and test directories\n",
    "split_dirs = ['train', 'val', 'test']\n",
    "create_directories(destination_image_dir, split_dirs)\n",
    "\n",
    "# Open separate output files for train, validation, and test data\n",
    "train_output_file = open(os.path.join(destination_image_dir, 'train_metadata.jsonl'), 'w')\n",
    "val_output_file = open(os.path.join(destination_image_dir, 'val_metadata.jsonl'), 'w')\n",
    "test_output_file = open(os.path.join(destination_image_dir, 'test_metadata.jsonl'), 'w')\n",
    "\n",
    "\n",
    "for category_folder in tqdm(sorted(os.listdir(data_folder))):\n",
    "    category_path = os.path.join(data_folder, category_folder)\n",
    "    for product_folder in sorted(os.listdir(category_path)):\n",
    "        \n",
    "        if product_folder not in all_product_names:                     \n",
    "            all_product_names.append(product_folder)\n",
    " \n",
    "            # Process each product using multiprocessing pool\n",
    "            process_product(product_folder, category_path, destination_image_dir, train_ratio, val_ratio)\n",
    "\n",
    "# Close the output files\n",
    "train_output_file.close()\n",
    "val_output_file.close()\n",
    "test_output_file.close()\n",
    "\n",
    "print(\"Output files and split directories created successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:04:07.003114300Z",
     "start_time": "2024-03-18T10:00:24.576308Z"
    }
   },
   "id": "a2184c49da72f9cc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "183165\n",
      "test_metadata.jsonl\n",
      "train\n",
      "551662\n",
      "train_metadata.jsonl\n",
      "val\n",
      "183989\n",
      "val_metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(destination_image_dir):\n",
    "    print(folder)\n",
    "    if '.jsonl' not in folder:\n",
    "        print(len(os.listdir(os.path.join(destination_image_dir, folder))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:06:12.363066100Z",
     "start_time": "2024-03-18T11:05:44.353313800Z"
    }
   },
   "id": "be108af9786c8229"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a68ba87fc7cfb1a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
