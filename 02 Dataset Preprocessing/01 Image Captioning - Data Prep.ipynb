{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation for Image Captioning models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2d70a72a5068f31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installing and Importing libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "775b91bb1d8d37bb"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-26T13:18:51.210695200Z",
     "start_time": "2024-03-26T13:18:51.196681300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data_folder = r\"C:\\\\Users\\\\likhi\\\\Documents\\\\02 Pycharm Datasets\\\\01 Master Thesis\\\\04 Product Data\\\\\"\n",
    "destination_image_dir = r'C:\\\\Users\\\\likhi\\\\Documents\\\\02 Pycharm Datasets\\\\01 Master Thesis\\\\06b Image_Captioning_Dataset\\\\imagefolder\\\\'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T13:18:51.457365100Z",
     "start_time": "2024-03-26T13:18:51.425814600Z"
    }
   },
   "id": "fd20530d7f3df1a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "15fe9f8f4f899f9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the train - val - test split of dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9814f9fcc5749c67"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def clean_descriptions(desc):\n",
    "    table = str.maketrans(' ', ' ', string.punctuation)\n",
    "    desc = desc.split(' ')\n",
    "    desc = [word.lower() for word in desc]\n",
    "    desc = [w.translate(table) for w in desc]\n",
    "    desc = [word for word in desc if len(word)>1]\n",
    "    desc = ' '.join(desc)\n",
    "    pattern = r'[0-9]'\n",
    "    desc = re.sub(pattern, '', desc)   \n",
    "    return desc\n",
    "\n",
    "\n",
    "# Function to create train, validation, and test directories\n",
    "def create_directories(root_dir, subdirs):\n",
    "    for subdir in subdirs:\n",
    "        os.makedirs(os.path.join(root_dir, subdir), exist_ok=True)\n",
    "\n",
    "# Function to copy files to train, validation, and test directories\n",
    "def copy_to_split(image_path, destination_dir, split):\n",
    "    shutil.copy(image_path, os.path.join(destination_dir, split))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T13:18:53.146808900Z",
     "start_time": "2024-03-26T13:18:53.145751900Z"
    }
   },
   "id": "2e4784f44a294a9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c6fa7872227ac74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to process a single product\n",
    "def process_product(product_folder, category_path, destination_image_dir, train_ratio, val_ratio):\n",
    "    all_images = []\n",
    "    product_path = os.path.join(category_path, product_folder)\n",
    "   \n",
    "    try:\n",
    "        data = json.load(open(os.path.join(product_path, product_folder + \".json\"), \"r\"))\n",
    "        \n",
    "        product_overview = data.get('product_overview', '')\n",
    "        product_overview = \"Product overview is \" + \",\".join([key + \" is \" + value \n",
    "                                                            for key, value in product_overview.items() \n",
    "                                                            if key.lower() not in ['color', 'colour']])\n",
    "        \n",
    "        # product_description = \"Product description is \" +\",\".join(data.get('description', ''))\n",
    "        # categories = \",\".join(data.get('categories', ''))\n",
    "        product_title = \"Product title is \" + data.get('Title', '')\n",
    "        final_description = product_title + \". \" + product_overview\n",
    "        \n",
    "        cleaned_final_description = clean_descriptions(final_description)\n",
    "        \n",
    "        num_words = len(cleaned_final_description.strip().split(\" \"))\n",
    "        \n",
    "        if num_words >= 350:\n",
    "            cleaned_final_description = clean_descriptions(product_title)\n",
    "            \n",
    "        image_names = [i for i in os.listdir(product_path) if '.jpg' in i]\n",
    "        all_images.extend(image_names)\n",
    "        \n",
    "        encoding = processor(cleaned_final_description, padding=\"max_length\",\n",
    "                             truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        if len(cleaned_final_description) > 40 and len(encoding) <= 512:\n",
    "            for img in image_names:\n",
    "                product_dict = {}  # Create a new dictionary for each iteration\n",
    "                product_dict[\"file_name\"] = img\n",
    "                product_dict[\"text\"] = cleaned_final_description\n",
    "                \n",
    "                # Write the dictionary to the appropriate output file based on the split\n",
    "                rand = random.random()\n",
    "                if rand < train_ratio:\n",
    "                    train_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "                    copy_to_split(os.path.join(product_path, img), destination_image_dir, 'train')\n",
    "                 \n",
    "                elif rand < train_ratio + val_ratio:\n",
    "                    val_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "                    copy_to_split(os.path.join(product_path, img), destination_image_dir, 'val')\n",
    "                else:\n",
    "                    test_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "                    copy_to_split(os.path.join(product_path, img), destination_image_dir, 'test')\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "       \n",
    "\n",
    "# Initialize lists to keep track of product names\n",
    "all_product_names = []\n",
    "\n",
    "# Define train-val-test split ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Create train, validation, and test directories\n",
    "split_dirs = ['train', 'val', 'test']\n",
    "create_directories(destination_image_dir, split_dirs)\n",
    "\n",
    "# Open separate output files for train, validation, and test data\n",
    "train_output_file = open(os.path.join(destination_image_dir, 'train', 'metadata.jsonl'), 'w')\n",
    "val_output_file = open(os.path.join(destination_image_dir, 'val', 'metadata.jsonl'), 'w')\n",
    "test_output_file = open(os.path.join(destination_image_dir, 'test', 'metadata.jsonl'), 'w')\n",
    "\n",
    "\n",
    "for category_folder in tqdm(sorted(os.listdir(data_folder))):\n",
    "    category_path = os.path.join(data_folder, category_folder)\n",
    "    for product_folder in sorted(os.listdir(category_path)):\n",
    "        \n",
    "        if product_folder not in all_product_names:                     \n",
    "            all_product_names.append(product_folder)\n",
    " \n",
    "            # Process each product using multiprocessing pool\n",
    "            process_product(product_folder, category_path, destination_image_dir, train_ratio, val_ratio)\n",
    "\n",
    "# Close the output files\n",
    "train_output_file.close()\n",
    "val_output_file.close()\n",
    "test_output_file.close()\n",
    "\n",
    "print(\"Output files and split directories created successfully.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2184c49da72f9cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ALT: Creating ONLY JSON File from scratch for the images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abf03c8aada12057"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T13:18:58.446075100Z",
     "start_time": "2024-03-26T13:18:56.998172200Z"
    }
   },
   "id": "689b43af8bf5c48d"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [17:19<00:00,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to process a single product\n",
    "def process_product(product_folder, category_path, destination_image_dir, train_ratio, val_ratio):\n",
    "    all_images = []\n",
    "    product_path = os.path.join(category_path, product_folder)\n",
    "   \n",
    "    try:\n",
    "        data = json.load(open(os.path.join(product_path, product_folder + \".json\"), \"r\"))\n",
    "        product_overview = data.get('product_overview', '')\n",
    "        product_overview = \"Product overview is \" + \" \".join([key + \" is \" + value \n",
    "                                                            for key, value in product_overview.items() \n",
    "                                                            if key.lower() not in ['color', 'colour']])\n",
    "        \n",
    "        # product_description = \"Product description is \" +\",\".join(data.get('description', ''))\n",
    "        # categories = \",\".join(data.get('categories', ''))\n",
    "        product_title = \"Product title is \" + data.get('Title', '')\n",
    "        final_description = product_title + \". \" + product_overview\n",
    "        \n",
    "    \n",
    "        cleaned_final_description = clean_descriptions(final_description)\n",
    "        \n",
    "        num_words = len(cleaned_final_description.strip().split(\" \"))\n",
    "        \n",
    "        if num_words > 350:\n",
    "            cleaned_final_description = clean_descriptions(product_title)\n",
    "         \n",
    "        encoding = processor(text=cleaned_final_description, padding=\"max_length\",\n",
    "                             truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        encoding = encoding['input_ids']\n",
    "        \n",
    "        encoding_shape = encoding.shape[1]\n",
    "        \n",
    "        image_names = [i for i in os.listdir(product_path) if '.jpg' in i]\n",
    "        all_images.extend(image_names)\n",
    "\n",
    "        if encoding_shape > 512:\n",
    "            for image_name in image_names:\n",
    "                os.remove(os.path.join(destination_image_dir, 'val', image_name))\n",
    "                print(\"Removed image \" + image_name)\n",
    "                print(\"Caption was : \", cleaned_final_description)\n",
    "        \n",
    "        if len(cleaned_final_description) > 1:\n",
    "            for img in image_names:\n",
    "                product_dict = {}  # Create a new dictionary for each iteration\n",
    "                product_dict[\"file_name\"] = img\n",
    "                product_dict[\"text\"] = cleaned_final_description\n",
    "\n",
    "                if os.path.exists(os.path.join(destination_image_dir, 'train', img)):\n",
    "                    train_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "\n",
    "                # if  os.path.exists(os.path.join(destination_image_dir, 'val', img)):\n",
    "                #     val_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "\n",
    "                else:\n",
    "                    test_output_file.write(json.dumps(product_dict) + '\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "        # print(f\"Error processing product {product_folder}: {e}\")\n",
    "        # print(f\"Path to product folder: {product_path}\")\n",
    "        # print(f\"Content of product folder: {os.listdir(product_path)}\")\n",
    "\n",
    "\n",
    "# Initialize lists to keep track of product names\n",
    "all_product_names = []\n",
    "\n",
    "# Define train-val-test split ratios\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Create train, validation, and test directories\n",
    "split_dirs = ['train', 'val', 'test']\n",
    "create_directories(destination_image_dir, split_dirs)\n",
    "\n",
    "# Open separate output files for train, validation, and test data\n",
    "train_output_file = open(os.path.join(destination_image_dir, 'train', 'metadata.jsonl'), 'w')\n",
    "# val_output_file = open(os.path.join(destination_image_dir, 'val', 'metadata.jsonl'), 'w')\n",
    "test_output_file = open(os.path.join(destination_image_dir, 'test', 'metadata.jsonl'), 'w')\n",
    "\n",
    "\n",
    "for category_folder in tqdm(sorted(os.listdir(data_folder))):\n",
    "    category_path = os.path.join(data_folder, category_folder)\n",
    "    for product_folder in sorted(os.listdir(category_path)):\n",
    "        \n",
    "        if product_folder not in all_product_names:                     \n",
    "            all_product_names.append(product_folder)\n",
    " \n",
    "            # Process each product using multiprocessing pool\n",
    "            process_product(product_folder, category_path, destination_image_dir, train_ratio, val_ratio)\n",
    "\n",
    "# Close the output files\n",
    "train_output_file.close()\n",
    "# val_output_file.close()\n",
    "test_output_file.close()\n",
    "\n",
    "print(\"Output files created successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T14:59:58.583180300Z",
     "start_time": "2024-03-26T14:42:39.153034Z"
    }
   },
   "id": "aa6d19e603840cdc"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "551894\n",
      "val\n",
      "184139\n",
      "test\n",
      "183346\n"
     ]
    }
   ],
   "source": [
    "for folder in ['train', 'val', 'test']:\n",
    "    if '.jsonl' not in folder:\n",
    "        print(folder)\n",
    "        print(len(os.listdir(os.path.join(destination_image_dir, folder))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T15:27:30.490490800Z",
     "start_time": "2024-03-26T15:26:33.313679700Z"
    }
   },
   "id": "be108af9786c8229"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking if images in the folder are present in the JSON file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d57b8fada732cbd7"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the folder -  test\n",
      "Loaded the JSON file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183341/183341 [21:46<00:00, 140.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing images -  221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folders = ['train', 'val', 'test']\n",
    "folders = ['test']\n",
    "\n",
    "for folder in folders:\n",
    "    \n",
    "    print(\"Checking the folder - \", folder)\n",
    "    json_data = []\n",
    "    f = open(os.path.join(destination_image_dir, folder, 'metadata.jsonl'), 'r')\n",
    "    for line in f:\n",
    "        json_data.append(json.loads(line))\n",
    "    json_data_filenames = [i['file_name'] for i in json_data]\n",
    "    \n",
    "    print(\"Loaded the JSON file\")\n",
    "    \n",
    "    images = [i for i in os.listdir(os.path.join(destination_image_dir, folder)) if '.jpg' in i]\n",
    "    \n",
    "    count = 0\n",
    "    for image in tqdm(images):\n",
    "        if image not in json_data_filenames:\n",
    "            count+=1\n",
    "            os.remove(os.path.join(destination_image_dir, folder, image))\n",
    "            \n",
    "    print(\"Missing images - \", count)\n",
    "        \n",
    "# 184140 - val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:29:16.591591900Z",
     "start_time": "2024-03-26T18:07:05.604497700Z"
    }
   },
   "id": "1a1ae10e2601253b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking if all the images are valid"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31dd7505be4ea055"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the folder -  train\n",
      "Got the list of images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 31159/551893 [00:29<10:05, 860.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_B00A7HRHIO_4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 76281/551893 [01:09<08:07, 976.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_B01MU075FD_49.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 464388/551893 [09:17<01:31, 957.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_B0C1WN5NLN_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 551893/551893 [10:53<00:00, 844.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images removed -  3\n",
      "Checking the folder -  val\n",
      "Got the list of images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184138/184138 [03:14<00:00, 947.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images removed -  0\n",
      "Checking the folder -  test\n",
      "Got the list of images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 14968/183345 [00:14<02:46, 1009.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_B00OC5FU8Q_0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 31178/183345 [00:32<02:40, 946.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_B073ZCX3LN_39.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 74644/183345 [01:20<02:10, 830.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_B08889VZN5_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 120067/183345 [02:14<01:12, 876.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_B09WWW8ZRJ_0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183345/183345 [03:48<00:00, 801.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images removed -  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "folders = ['train', 'val', 'test']\n",
    "\n",
    "for folder in folders:\n",
    "    \n",
    "    print(\"Checking the folder - \", folder)\n",
    "    json_data = []\n",
    "    image_folder = os.path.join(destination_image_dir, folder)\n",
    "    \n",
    "    images = [i for i in os.listdir(image_folder) if '.jpg' in i]\n",
    "    \n",
    "    print(\"Got the list of images\")\n",
    "    count = 0\n",
    "    \n",
    "    for img in tqdm(images):\n",
    "        image_path = os.path.join(image_folder, img)\n",
    "        try:\n",
    "            Image.open(image_path)\n",
    "        except Exception as e:\n",
    "            print(img)\n",
    "            count+=1\n",
    "            os.remove(image_path)\n",
    "  \n",
    "    print(\"Images removed - \", count)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T16:51:41.564284100Z",
     "start_time": "2024-03-26T16:32:58.603400100Z"
    }
   },
   "id": "a030451b972381e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f528bf66c862b4c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving the Dataset to PyTorch Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7805df026a98472"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Path to the folder containing the data\n",
    "root = r\"C:/Users/likhi/Documents/02 Pycharm Datasets/01 Master Thesis/06b Image_Captioning_Dataset/imagefolder/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T11:48:08.228719200Z",
     "start_time": "2024-03-26T11:48:08.207972Z"
    }
   },
   "id": "223d278b02064ba8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200GB\n"
     ]
    }
   ],
   "source": [
    "# Set the environment variable ARROW_LARGE_MEMORY_TEST to '20GB'\n",
    "os.environ['ARROW_LARGE_MEMORY_TEST'] = '200GB'\n",
    "\n",
    "block_size = os.environ.get('ARROW_LARGE_MEMORY_TEST')\n",
    "print(block_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T11:48:08.511924100Z",
     "start_time": "2024-03-26T11:48:08.448636700Z"
    }
   },
   "id": "63d83089c6c968e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the train dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b04da1c50157461"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/551891 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ae0b1238a064e009f6d30208a68b56c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Computing checksums:   6%|5         | 33027/551891 [00:05<01:18, 6603.61it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e40dff15ae7b4da6a8d2155f66acc7da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7ad433b48094f15a5615e385f7867e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "Dataset({\n",
      "    features: ['image', 'text'],\n",
      "    num_rows: 551890\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Define the paths to your train, validation, and test data directories\n",
    "train_data_path = root +'train/'\n",
    "\n",
    "# Load the train, validation, and test datasets\n",
    "train_dataset = load_dataset(\"imagefolder\", data_dir=train_data_path, split='train')\n",
    "# Optionally, you can inspect the loaded datasets\n",
    "print(\"Train Dataset:\")\n",
    "print(train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:13:57.203845500Z",
     "start_time": "2024-03-26T16:51:41.571971700Z"
    }
   },
   "id": "88d7f51eae8836d3"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "Saving the dataset (0/36 shards):   0%|          | 0/551890 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c253022c01e043309c82b86c655038b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(root + 'train_dataset_version_6/'):\n",
    "    os.mkdir(root + 'train_dataset_version_6/')\n",
    "    \n",
    "train_dataset.save_to_disk(root + 'train_dataset_version_6/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:34:27.015078500Z",
     "start_time": "2024-03-26T17:13:57.212819900Z"
    }
   },
   "id": "e4f64a2047cdab3e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the validation dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce43007edb58102e"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/184139 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81d04ed949594eb59f6d202e29d222d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dataset:\n",
      "Dataset({\n",
      "    features: ['image', 'text'],\n",
      "    num_rows: 184138\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "val_data_path = root +'val/'\n",
    "\n",
    "val_dataset = load_dataset(\"imagefolder\", data_dir=val_data_path, split='train')\n",
    "\n",
    "print(\"Validation Dataset:\")\n",
    "print(val_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T14:37:19.226623400Z",
     "start_time": "2024-03-26T14:31:26.984973800Z"
    }
   },
   "id": "6c8f9c8d90813950"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "Saving the dataset (0/12 shards):   0%|          | 0/184138 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ded4718c81fd4ca8bdb812adb7329559"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(root + 'val_dataset_version_6/'):\n",
    "    os.mkdir(root + 'val_dataset_version_6/')\n",
    "    \n",
    "val_dataset.save_to_disk(root + 'val_dataset_version_6/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T14:42:24.668987800Z",
     "start_time": "2024-03-26T14:37:19.218161300Z"
    }
   },
   "id": "ef32ff4481a5b5cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## QUALITY CHECK"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "532c80a97cfddd41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking caption length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b64a42834129d54d"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImageCaptioningDataset(Dataset):\n",
    "    def __init__(self, dataset, processor):\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        encoding = self.processor(images=item[\"image\"],\n",
    "                                  text=item[\"text\"],\n",
    "                                  truncation=True,\n",
    "                                  padding=\"max_length\", return_tensors=\"pt\")\n",
    "        # remove batch dimension\n",
    "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
    "       \n",
    "        return encoding\n",
    "\n",
    "from transformers import AutoProcessor, BlipForConditionalGeneration\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "val_dataset = ImageCaptioningDataset(val_dataset, processor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T14:31:01.467694800Z",
     "start_time": "2024-03-26T14:30:59.198487300Z"
    }
   },
   "id": "4dc08a89d57300c8"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Iterate through the dataset and print the length of each input sequence\n",
    "indices_to_exclude = [20601, 20602, 32084, 35422, 77578, 77776, 77891,\n",
    "           77893, 88724, 88783, 88784, 97167, 97168, 98892,\n",
    "           122296, 125396, 125846, 141298, 149114, 149123, 169166, 172201, 179787,\n",
    "                      179788, 179789, 179790, 180489]\n",
    "\n",
    "\n",
    "for idx in tqdm(indices_to_exclude):\n",
    "    sample = val_dataset[idx]\n",
    "    # The length of the input_ids tensor indicates the length of the input sequence\n",
    "    input_ids_length = sample['input_ids'].shape[0]\n",
    "\n",
    "    if input_ids_length > 512:\n",
    "        print(f\"Length of input sequence {idx}: {input_ids_length}\")\n",
    "        generated_caption = processor.batch_decode(sample['input_ids'], skip_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7100ada1e6f7e17"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the test dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2561878ddb7ed8bd"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/183121 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc716e3078194ea5bb0577d68306c34a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Computing checksums:  26%|##6       | 48042/183121 [00:05<00:14, 9608.19it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2df82cc3282e4c1c8ce9b5b800a1bbab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "045e519117c94148a4dceda8511e8440"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset:\n",
      "Dataset({\n",
      "    features: ['image', 'text'],\n",
      "    num_rows: 183120\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "test_data_path = root +'test/'\n",
    "\n",
    "test_dataset = load_dataset(\"imagefolder\", data_dir=test_data_path, split='train')\n",
    "\n",
    "print(\"Test Dataset:\")\n",
    "print(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:35:03.782093500Z",
     "start_time": "2024-03-26T18:29:16.599751300Z"
    }
   },
   "id": "388717f242d2fffc"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "Saving the dataset (0/11 shards):   0%|          | 0/183120 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37132d4f770548ccb147ca178538af4e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(root + 'test_dataset_version_6/'):\n",
    "    os.mkdir(root + 'test_dataset_version_6/')\n",
    "    \n",
    "test_dataset.save_to_disk(root + 'test_dataset_version_6/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:41:52.743403100Z",
     "start_time": "2024-03-26T18:35:03.778626Z"
    }
   },
   "id": "411bb7325c3c9155"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b96ec826c4114e9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
